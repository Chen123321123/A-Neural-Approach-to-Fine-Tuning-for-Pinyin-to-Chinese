{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2XJgTkE_n1n"
      },
      "source": [
        "# mT5-base Finetune\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcXBZZwI_rER",
        "outputId": "3b5d7fbc-7eb1-4ba0-d6f9-df5e963b172d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.4)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e6f0f6cb0f5b13cfddf53c2bbb2e6888574c733813e0420dafd29938aef9f044\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets bitsandbytes evaluate sacrebleu rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u5Gcd4S_ucg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRzJSg8X_7FA"
      },
      "outputs": [],
      "source": [
        "csv_path = \"../data/inputs/standard/train.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "examples = []\n",
        "for _, row in df.iterrows():\n",
        "    if pd.notna(row.get(\"Pinyin\")) and pd.notna(row.get(\"Chinese\")):\n",
        "        examples.append({\n",
        "            \"input\": row[\"Pinyin\"],\n",
        "            \"target\": row[\"Chinese\"]\n",
        "        })\n",
        "dataset = Dataset.from_pandas(pd.DataFrame(examples))\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "eval_size = len(dataset) - train_size\n",
        "train_subset, eval_subset = torch.utils.data.random_split(dataset, [train_size, eval_size])\n",
        "\n",
        "train_dataset = Dataset.from_list([dataset[i] for i in train_subset.indices])\n",
        "eval_dataset = Dataset.from_list([dataset[i] for i in eval_subset.indices])\n",
        "del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyWe1xLk_9Fe",
        "outputId": "641641d5-9200-44c5-ccda-30d30114e18c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
            "The class this function is called from is 'MT5Tokenizer'.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.mt5.tokenization_mt5.MT5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "model_name = \"google/mt5-base\"\n",
        "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "72d371f421924146b3605ec7fdd08543",
            "209ce9e98e5546119d9e1450f4aaae20",
            "6fb0265e6a934a728f25ac35824a9559",
            "db904bd5c5774f27a7d4ffb241211cab",
            "c64a1a323af546019ddefb1874390f2b",
            "7fa5747e4f4f4443b6bc51b6e88b5579",
            "4b138ace6a884942a3de6a5288b1a632",
            "c79b434b0178432789d9025c8f753ea4",
            "56dcaae191ba4d1e9f6d7e05fd78b193",
            "07454b67c8224a9e8e78c8e22d1d196e",
            "586538c0121040e9a9a95b7fcdcdac8a",
            "82879fca0a2c4ed7a784bc1632e16515",
            "b9a6f02cca8f48a6a4ff562603cdfc4a",
            "5f0fa7606a414b9485c9fce46b90cfe9",
            "a8f52e09539c4c41a121b388fc69a77e",
            "232ad58ee3654c229c916f2bd1a33497",
            "fa9082e099b5484f86ad4ad5883aaf20",
            "f30f36cff72a4e08af56e8102b5b2e4d",
            "7f4138291f0c40e0b18301b24dd91a56",
            "33d4415d95f14290b586f6c6798b619b",
            "08eb823230f64340a3dc18cef09c743b",
            "83a9dfebda2b48fb83e4304cc8ef9f01"
          ]
        },
        "id": "VGFuPCRRAJ9w",
        "outputId": "af734558-43cf-48b5-d744-0d2a371d784a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72d371f421924146b3605ec7fdd08543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14959 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82879fca0a2c4ed7a784bc1632e16515",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3740 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "    prefix = \"拼音转中文：\"\n",
        "    inputs = [prefix + text for text in examples[\"input\"]]\n",
        "    targets = examples[\"target\"] # Chinese\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        text_target=targets,\n",
        "        truncation=True,\n",
        "        padding=\"longest\"\n",
        "    )\n",
        "\n",
        "    label_ids = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
        "        for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "    model_inputs[\"labels\"] = label_ids\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize the entire dataset\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHnw4vKGALm0",
        "outputId": "00d54439-e600-4723-fa1a-c12a72a90c9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-12-ac1d6d21c2b4>:89: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "bleu = load(\"bleu\")\n",
        "chrf = load(\"chrf\")\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "def space_chars(text):\n",
        "    return \" \".join(list(text.strip()))\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    print(\"Pred shape:\", np.array(preds).shape)\n",
        "    print(\"Labels shape:\", np.array(labels).shape)\n",
        "\n",
        "    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
        "\n",
        "    # clip predictions to valid token ID range\n",
        "    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
        "\n",
        "    invalid = [(i, val) for i, row in enumerate(labels) for val in row if val < 0 or val >= tokenizer.vocab_size]\n",
        "    if invalid:\n",
        "        print(\"Invalid token IDs found:\", invalid[:5])  # print just a few for now\n",
        "        raise ValueError(\"Found token ids out of tokenizer vocab range.\")\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Normalize whitespace, remove special tokens, etc. if needed\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [label.strip() for label in decoded_labels]\n",
        "\n",
        "    # Character-level accuracy\n",
        "    char_correct = 0\n",
        "    char_total = 0\n",
        "    for pred, label in zip(decoded_preds, decoded_labels):\n",
        "        char_total += len(label)\n",
        "        char_correct += sum(p == l for p, l in zip(pred, label))\n",
        "\n",
        "    char_accuracy = char_correct / char_total if char_total > 0 else 0.0\n",
        "\n",
        "    spaced_preds = [space_chars(pred) for pred in decoded_preds]\n",
        "    spaced_labels = [space_chars(label) for label in decoded_labels]\n",
        "\n",
        "    # BLEU (optional, use for logging or reference)\n",
        "    bleu_result = bleu.compute(predictions=spaced_preds, references=[[lbl] for lbl in spaced_labels])\n",
        "    bleu_score = bleu_result[\"bleu\"]\n",
        "\n",
        "    # chrf\n",
        "    chrf_score = chrf.compute(predictions=spaced_preds, references=[[lbl] for lbl in spaced_labels])[\"score\"]\n",
        "\n",
        "    # ROUGE (use spaced strings so it treats each char as a token)\n",
        "    rouge_result = rouge.compute(predictions=spaced_preds, references=spaced_labels, use_stemmer=False)\n",
        "    rouge1 = rouge_result[\"rouge1\"]\n",
        "    rouge2 = rouge_result[\"rouge2\"]\n",
        "    rougeL = rouge_result[\"rougeL\"]\n",
        "\n",
        "    return {\n",
        "        \"char_accuracy\": char_accuracy,\n",
        "        \"chrf\": chrf_score,\n",
        "        \"bleu\": bleu_score,\n",
        "        \"rouge1\": rouge1,\n",
        "        \"rouge2\": rouge2,\n",
        "        \"rougeL\": rougeL,\n",
        "    }\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mt5_pinyin_to_chinese\",  \n",
        "    evaluation_strategy=\"steps\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16, \n",
        "    per_device_eval_batch_size=16,   \n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,     \n",
        "    num_train_epochs=20,         \n",
        "    predict_with_generate=True,\n",
        "    load_best_model_at_end=True,\n",
        "    greater_is_better=True,\n",
        "    metric_for_best_model=\"char_accuracy\",\n",
        "    gradient_accumulation_steps=8,\n",
        "    save_steps=200,                    \n",
        "    logging_steps=100,         \n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    eval_steps=200,          \n",
        "    save_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Fdvc8sTATTo",
        "outputId": "eb08db83-ddbf-49ed-bbf9-05da467dd718"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpipiroy03\u001b[0m (\u001b[33mpipiroy03-simon-fraser-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250402_041322-dq4wavpm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pipiroy03-simon-fraser-university/huggingface/runs/dq4wavpm' target=\"_blank\">./mt5_pinyin_to_chinese</a></strong> to <a href='https://wandb.ai/pipiroy03-simon-fraser-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/pipiroy03-simon-fraser-university/huggingface' target=\"_blank\">https://wandb.ai/pipiroy03-simon-fraser-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/pipiroy03-simon-fraser-university/huggingface/runs/dq4wavpm' target=\"_blank\">https://wandb.ai/pipiroy03-simon-fraser-university/huggingface/runs/dq4wavpm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2320/2320 1:53:32, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Char Accuracy</th>\n",
              "      <th>Chrf</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.042900</td>\n",
              "      <td>4.546898</td>\n",
              "      <td>0.027322</td>\n",
              "      <td>1.736691</td>\n",
              "      <td>0.003458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.768000</td>\n",
              "      <td>3.325936</td>\n",
              "      <td>0.148407</td>\n",
              "      <td>9.137683</td>\n",
              "      <td>0.087714</td>\n",
              "      <td>0.014260</td>\n",
              "      <td>0.012451</td>\n",
              "      <td>0.014216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>4.120700</td>\n",
              "      <td>2.902268</td>\n",
              "      <td>0.209706</td>\n",
              "      <td>12.575057</td>\n",
              "      <td>0.133871</td>\n",
              "      <td>0.015242</td>\n",
              "      <td>0.013359</td>\n",
              "      <td>0.015196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.746700</td>\n",
              "      <td>2.644571</td>\n",
              "      <td>0.261885</td>\n",
              "      <td>15.501857</td>\n",
              "      <td>0.173246</td>\n",
              "      <td>0.016079</td>\n",
              "      <td>0.013738</td>\n",
              "      <td>0.016038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.468000</td>\n",
              "      <td>2.447698</td>\n",
              "      <td>0.309405</td>\n",
              "      <td>17.980902</td>\n",
              "      <td>0.205804</td>\n",
              "      <td>0.015998</td>\n",
              "      <td>0.013760</td>\n",
              "      <td>0.015865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.248700</td>\n",
              "      <td>2.315383</td>\n",
              "      <td>0.338939</td>\n",
              "      <td>19.830784</td>\n",
              "      <td>0.229717</td>\n",
              "      <td>0.015852</td>\n",
              "      <td>0.013837</td>\n",
              "      <td>0.015896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.090700</td>\n",
              "      <td>2.205347</td>\n",
              "      <td>0.367484</td>\n",
              "      <td>21.390649</td>\n",
              "      <td>0.249524</td>\n",
              "      <td>0.016178</td>\n",
              "      <td>0.014037</td>\n",
              "      <td>0.016121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.950900</td>\n",
              "      <td>2.130654</td>\n",
              "      <td>0.389248</td>\n",
              "      <td>22.653187</td>\n",
              "      <td>0.265482</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.014439</td>\n",
              "      <td>0.016310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.870600</td>\n",
              "      <td>2.075549</td>\n",
              "      <td>0.398115</td>\n",
              "      <td>23.410806</td>\n",
              "      <td>0.274536</td>\n",
              "      <td>0.016178</td>\n",
              "      <td>0.014037</td>\n",
              "      <td>0.016121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.807600</td>\n",
              "      <td>2.038210</td>\n",
              "      <td>0.406011</td>\n",
              "      <td>23.958040</td>\n",
              "      <td>0.280952</td>\n",
              "      <td>0.016221</td>\n",
              "      <td>0.014305</td>\n",
              "      <td>0.016176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.767200</td>\n",
              "      <td>2.018388</td>\n",
              "      <td>0.411137</td>\n",
              "      <td>24.340307</td>\n",
              "      <td>0.285728</td>\n",
              "      <td>0.016221</td>\n",
              "      <td>0.014305</td>\n",
              "      <td>0.016176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n",
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [234/234 03:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred shape: (3740, 21)\n",
            "Labels shape: (3740, 46)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pinyin: ta xi huan na ta de tong xue kai wan xiao\n",
            "Chinese: 他喜欢那他的同学开课\n",
            "\n",
            "Pinyin: ru guo you ji hui wo jiang qu kan na bu dian ying\n",
            "Chinese: 如果有机会我将去看那部电影\n",
            "\n",
            "Pinyin: cong zhe ge jiao du lai kan hua zhong de nv zi mian dai wei xiao\n",
            "Chinese: 从这个教堂来看画中的女孩面带为小\n",
            "\n",
            "Pinyin: ta song wo de ji nian pin hen xiao er qie bu zhi qian\n",
            "Chinese: 他送我的年度礼物很小但是并不之前\n",
            "\n",
            "Pinyin: zhe ben shu shi ta yi qian xie de ju ben de kuo chong\n",
            "Chinese: 这本书是他以前写的简短的短篇\n",
            "\n",
            "Pinyin: wo men zhen de chu yu kun jing mei ren zhao gu ying er\n",
            "Chinese: 我们真得处於荒凉没有人照护英勇\n",
            "\n",
            "Pinyin: ta shi huo de yi xue jiao ke shu\n",
            "Chinese: 他是计算机的一名计算机\n",
            "\n",
            "Pinyin: wo dong yi dian er de yu\n",
            "Chinese: 我握一点儿的泪\n",
            "\n",
            "Pinyin: ci li shi yi zhong zi ran xian xiang\n",
            "Chinese: 地球是一种自远现象\n",
            "\n",
            "Pinyin: qi shi nian dai shi chao duan qun shi dai\n",
            "Chinese: 历史年代是超长年代\n",
            "\n",
            "Pinyin: ji qi sheng chan yi jing dai ti le shou gong lao zuo\n",
            "Chinese: 计算机工作已经完成了手工作业\n",
            "\n",
            "Pinyin: lao zi shuang fang zhi jian cun zai da liang mao dun\n",
            "Chinese: 小孩双方之间存在大面积马达\n",
            "\n",
            "Pinyin: kong pa wo de fang wei gan hen cha yin ci wo rong yi mi lu\n",
            "Chinese: 巡覆我的房间感到很沉因为我只能迷路\n",
            "\n",
            "Pinyin: cao shang zhan man le lu zhu\n",
            "Chinese: 海岸上散满了树枝\n",
            "\n",
            "Pinyin: cai zheng bu yuan ze shang fan dui zhe xie ti yi\n",
            "Chinese: 财政不愿上反对这些政策\n",
            "\n",
            "Pinyin: zheng fu de tong gao yi shi wei mai xiang jie jue ba gong wen ti de yi bu\n",
            "Chinese: 政府的谈判是一事向农夫解决把工作的问题的一部分\n",
            "\n",
            "Pinyin: wo zheng xie yi feng zheng zhong qi shi de hui xin\n",
            "Chinese: 我正写一封信中一切的回忆\n",
            "\n",
            "Pinyin: yi ming fei tu zai jie shang zhi zao shi duan yin ren zhu mu qi yu fei tu ze qiang jie yin hang\n",
            "Chinese: 一位弗雷特在结上只剩下一根因人主昏于弗雷特以强迫其结实\n",
            "\n",
            "Pinyin: xiang cun de tian ye li qian mo zong heng\n",
            "Chinese: 城镇的天气里冷漠总欢\n",
            "\n",
            "Pinyin: qi ping di shi qi jun yun zai yi ge ping mian shang huo liu bian pai ban\n",
            "Chinese: 斜坡地是斜坡运在一个坡面上或斜坡挂板\n",
            "\n",
            "Pinyin: wo de wai zu fu yao lai le\n",
            "Chinese: 我的外祖父要来了\n",
            "\n",
            "Pinyin: gai tiao kuan nei rong ru xia\n",
            "Chinese: 该条条内空如下\n",
            "\n",
            "Pinyin: xian cheng li zhe you bai er ba shi li\n",
            "Chinese: 先成里者有白而把石头\n",
            "\n",
            "Pinyin: zhe zhong qi che ke yi zai zi shen chang du fan wei nei diao tou\n",
            "Chinese: 这种汽车可以在身体中不停地走走\n",
            "\n",
            "Pinyin: wo men qian mian de na liang qi che tu ran zhuan ru zuo bian de xiao lu shang qu le\n",
            "Chinese: 我们前面的那辆汽车突然转入小路上的小路上了\n",
            "\n",
            "Pinyin: yan zi zai kong zhong lve guo\n",
            "Chinese: 鸟子在空中飞过\n",
            "\n",
            "Pinyin: wo kao fu mu fu yang mian qiang guo huo\n",
            "Chinese: 我建议服毛服装面强行\n",
            "\n",
            "Pinyin: fu bai de yuan yin chuan bu fu bai huo fu xiu de gen yuan\n",
            "Chinese: 腐蚀的原因穿不腐蚀或腐朽的根源\n",
            "\n",
            "Pinyin: tong guo guan dao ba re shui cong guo lu shu song dao san re qi li\n",
            "Chinese: 通过测量把油水从国外存储到三油区\n",
            "\n",
            "Pinyin: lian xu ji ge xiao shi ta dou zai ai sheng tan qi xi wang neng cong ta mu qin na nong dian qian\n",
            "Chinese: 连忙几个小时他们都在爱生谈起希望能从他母亲那村里去\n",
            "\n",
            "Pinyin: fei ji yi mei xiao shi 900 gong li de su du fei xing\n",
            "Chinese: 保险一每小时900万元的成本保险\n",
            "\n",
            "Pinyin: a ke ba wan hong hai de yi ge hai wan zai xi nai ban dao ji sha te a la bo xi bei bu zhi jian ta chang qi yi lai zai zhong dong ju you zhong yao de zhan lve xing\n",
            "Chinese: 阿克把王洪海的一个男孩在西尼班到几层塔阿拉伯斯贝贝贝然他开始在中场由中要的比赛形式\n",
            "\n",
            "Pinyin: ta bu dan bu cheng ren fan er zhi wu qi ci\n",
            "Chinese: 他不但不成人反而只为其次\n",
            "\n",
            "Pinyin: ci shu bian zuan zhe bi xu jing yu gei ci yu xia ding yi de ji qiao\n",
            "Chinese: 数字编写者必须经过给数字下定一的程序\n",
            "\n",
            "Pinyin: xiao huo shan kou yi zhong di bu ping tan da zhi cheng yuan xing de huo shan bao fa hou xing cheng de sheng man shui de di wa di\n",
            "Chinese: 小火山龟一种地不平坦地形成原始性的火山干发后形成的生动水的地壁地\n",
            "\n",
            "Pinyin: ni ying gai duo dao ge di zou zou yi zeng guang jian shi\n",
            "Chinese: 你应该多到一个地方走走以加强光景\n",
            "\n",
            "Pinyin: bu ding dai ming ci de yong yu dai ci\n",
            "Chinese: 不确定日期的用於日期\n",
            "\n",
            "Pinyin: wo dui dian nao de wei xiu bao yang hen zai hang\n",
            "Chinese: 我对地底的威士忌保护很在坏\n",
            "\n",
            "Pinyin: ta wu xing cha mei you yi shi dao cun zai de wei xian\n",
            "Chinese: 他无形查没有一事到处的地方\n",
            "\n",
            "Pinyin: shi you shu chu guo jia zu zhi dong jie shi you shu chu jia ge kan zhang\n",
            "Chinese: 由有书出版国家组织联络由有书出版公司一个看官\n",
            "\n",
            "Pinyin: ri ben di que shi ge mei li de guo jia dan zui jin ri ben de da du shi yi bei wu ran\n",
            "Chinese: 冷冰地是个美利的国家但最严重冷冰的程度是一次无穷\n",
            "\n",
            "Pinyin: you deng fa chu rou he de liang guang\n",
            "Chinese: 有洞窟出露和的光芒\n",
            "\n",
            "Pinyin: zhe gu zhang shu yue lai wei yin qi zhu yi\n",
            "Chinese: 这篇文章发表来为解释主意\n",
            "\n",
            "Pinyin: shi jia yi jian hui sheng cang cu chu li diao bu zu wei qu\n",
            "Chinese: 警察一决会生气冲出路道不由去\n",
            "\n",
            "Pinyin: wo zai qiang shang ding le yi ge tu ding ran hou zai shang mian gua le yi zhang xiao tu pian\n",
            "Chinese: 我在墙上定了一个定定然后在上面挂了一个小图片\n",
            "\n",
            "Pinyin: ta zhang de jiao rou mei li\n",
            "Chinese: 他张的脚轮美丽\n",
            "\n",
            "Pinyin: ta ba ri ji suo zai shang ceng chou ti li\n",
            "Chinese: 他把葡萄树在上层钻地里\n",
            "\n",
            "Pinyin: wo men jing chong fen tao lun jue ding qian wang niu jin\n",
            "Chinese: 我们经常讨论决定前往宁静\n",
            "\n",
            "Pinyin: qing wu zai sheng qi de shi hou qu ban ru ci zhong yao de shi qing\n",
            "Chinese: 清晨在生气的时候去转如这次要的时光\n",
            "\n",
            "Pinyin: gong zhu bei na ge ke wu de mo shu shi tou tou dai dao le yi ge huang dao shang\n",
            "Chinese: 工人被那个可贵的模样时头头摔到了一个花朵上\n",
            "\n",
            "Pinyin: wo men dou xi guan yu suo shou de jiao yang\n",
            "Chinese: 我们都喜欢所受的教训\n",
            "\n",
            "Pinyin: ta de qian xun yu kuai de yang zi dou shi zhuang chu lai de\n",
            "Chinese: 他的前途与快的姿态都是装出来的\n",
            "\n",
            "Pinyin: fang she xing cai liao zhu cun zai fang fu she de te shu rong qi nei\n",
            "Chinese: 建筑物设计位于建筑物的特写结构内\n",
            "\n",
            "Pinyin: zi cong mou ji su xue xiao chuan chu you ren xi du zhi hou gao nian ji you ji ge nan sheng yi bei kai chu\n",
            "Chinese: 自从某学校毕业有人逝灭之后每年有几个难生一被开出\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "trainer.save_model(\"./mt5_pinyin_to_chinese_final\")\n",
        "# # ----------------- VALIDATE -------------------\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
        "\n",
        "model_path = \"./mt5_pinyin_to_chinese_final\"  # Adjust path if different\n",
        "tokenizer = MT5Tokenizer.from_pretrained(model_path)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "test_csv_path = \"eval.csv\"\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "if \"Pinyin\" not in df_test.columns:\n",
        "    raise ValueError(\"The CSV file must contain a column with Chinese words.\")\n",
        "\n",
        "def generate_chinese_text(pinyin_sentence):\n",
        "    input_text = \"拼音转中文：\" + pinyin_sentence\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=\"longest\", truncation=True)[\"input_ids\"]\n",
        "    input_ids = torch.LongTensor(input_ids).view(1, -1).to(model.device)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=64,\n",
        "        num_beams=4,  # new\n",
        "        early_stopping=True,  # new\n",
        "        num_return_sequences=1, # new\n",
        "    )\n",
        "    prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    print(f\"Pinyin: {pinyin_sentence}\\nChinese: {prediction}\\n\")\n",
        "\n",
        "    return prediction\n",
        "\n",
        "df_test[\"Predicted Chinese\"] = df_test[\"Pinyin\"].apply(generate_chinese_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-fYgbTqZKAC"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./mt5_base_pinyin_to_chinese_final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag4Gfl2NY2Ze"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YAu5Q_slznw"
      },
      "outputs": [],
      "source": [
        "del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-DO14RlKn6U",
        "outputId": "ffa15303-4e1f-4d0a-a1e4-1ce66a68aa43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: t5_pinyin_to_chinese_final// (stored 0%)\n",
            "  adding: t5_pinyin_to_chinese_final//config.json (deflated 48%)\n",
            "  adding: t5_pinyin_to_chinese_final//generation_config.json (deflated 29%)\n",
            "  adding: t5_pinyin_to_chinese_final//added_tokens.json (deflated 83%)\n",
            "  adding: t5_pinyin_to_chinese_final//model.safetensors (deflated 7%)\n",
            "  adding: t5_pinyin_to_chinese_final//training_args.bin (deflated 51%)\n",
            "  adding: t5_pinyin_to_chinese_final//tokenizer_config.json (deflated 94%)\n",
            "  adding: t5_pinyin_to_chinese_final//spiece.model (deflated 46%)\n",
            "  adding: t5_pinyin_to_chinese_final//special_tokens_map.json (deflated 85%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r mt5_base_pinyin_to_chinese_final.zip mt5_base_pinyin_to_chinese_final//"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kmGgTqzQNBbs",
        "outputId": "502506f6-483a-4a94-b9f6-fb5af7190c83"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_10ff7b43-1274-439d-bd38-610b2c491fe5\", \"mt5_pinyin_to_chinese.zip\", 4327440380)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/mt5_base_pinyin_to_chinese.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lkY7I9Rl_Ydz",
        "Mlr1o5ncPU0w"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07454b67c8224a9e8e78c8e22d1d196e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08eb823230f64340a3dc18cef09c743b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209ce9e98e5546119d9e1450f4aaae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa5747e4f4f4443b6bc51b6e88b5579",
            "placeholder": "​",
            "style": "IPY_MODEL_4b138ace6a884942a3de6a5288b1a632",
            "value": "Map: 100%"
          }
        },
        "232ad58ee3654c229c916f2bd1a33497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d4415d95f14290b586f6c6798b619b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b138ace6a884942a3de6a5288b1a632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56dcaae191ba4d1e9f6d7e05fd78b193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "586538c0121040e9a9a95b7fcdcdac8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0fa7606a414b9485c9fce46b90cfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f4138291f0c40e0b18301b24dd91a56",
            "max": 3740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33d4415d95f14290b586f6c6798b619b",
            "value": 3740
          }
        },
        "6fb0265e6a934a728f25ac35824a9559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79b434b0178432789d9025c8f753ea4",
            "max": 14959,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56dcaae191ba4d1e9f6d7e05fd78b193",
            "value": 14959
          }
        },
        "72d371f421924146b3605ec7fdd08543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_209ce9e98e5546119d9e1450f4aaae20",
              "IPY_MODEL_6fb0265e6a934a728f25ac35824a9559",
              "IPY_MODEL_db904bd5c5774f27a7d4ffb241211cab"
            ],
            "layout": "IPY_MODEL_c64a1a323af546019ddefb1874390f2b"
          }
        },
        "7f4138291f0c40e0b18301b24dd91a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa5747e4f4f4443b6bc51b6e88b5579": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82879fca0a2c4ed7a784bc1632e16515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9a6f02cca8f48a6a4ff562603cdfc4a",
              "IPY_MODEL_5f0fa7606a414b9485c9fce46b90cfe9",
              "IPY_MODEL_a8f52e09539c4c41a121b388fc69a77e"
            ],
            "layout": "IPY_MODEL_232ad58ee3654c229c916f2bd1a33497"
          }
        },
        "83a9dfebda2b48fb83e4304cc8ef9f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8f52e09539c4c41a121b388fc69a77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08eb823230f64340a3dc18cef09c743b",
            "placeholder": "​",
            "style": "IPY_MODEL_83a9dfebda2b48fb83e4304cc8ef9f01",
            "value": " 3740/3740 [00:01&lt;00:00, 2432.89 examples/s]"
          }
        },
        "b9a6f02cca8f48a6a4ff562603cdfc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9082e099b5484f86ad4ad5883aaf20",
            "placeholder": "​",
            "style": "IPY_MODEL_f30f36cff72a4e08af56e8102b5b2e4d",
            "value": "Map: 100%"
          }
        },
        "c64a1a323af546019ddefb1874390f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79b434b0178432789d9025c8f753ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db904bd5c5774f27a7d4ffb241211cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07454b67c8224a9e8e78c8e22d1d196e",
            "placeholder": "​",
            "style": "IPY_MODEL_586538c0121040e9a9a95b7fcdcdac8a",
            "value": " 14959/14959 [00:06&lt;00:00, 2394.62 examples/s]"
          }
        },
        "f30f36cff72a4e08af56e8102b5b2e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa9082e099b5484f86ad4ad5883aaf20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
